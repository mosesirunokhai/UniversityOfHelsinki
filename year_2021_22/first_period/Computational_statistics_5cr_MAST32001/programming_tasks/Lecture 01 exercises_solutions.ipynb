{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Mathematics and Statistics  \n",
    "MAST32001 Computational Statistics, Autumn 2021  \n",
    "Luigi Acerbi  \n",
    "Based on notebook by Antti Honkela\n",
    "\n",
    "# Lecture 1: Floating point numbers and numerics of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating point number basics\n",
    "\n",
    "Real numbers are typically represented as floating point numbers in computers. Floating point numbers use a fixed storage size and hence can offer only finite precision. Floating point numbers do not fulfill the usual axioms of real numbers, which means they can sometimes behave in unexpected ways.\n",
    "\n",
    "Background reading on floating point numbers:\n",
    "\n",
    "http://floating-point-gui.de/formats/fp/  \n",
    "http://floating-point-gui.de/errors/rounding/  \n",
    "http://floating-point-gui.de/errors/comparison/  \n",
    "http://floating-point-gui.de/errors/propagation/  \n",
    "https://hal.archives-ouvertes.fr/hal-00128124v5/document  \n",
    "and references therein.\n",
    "\n",
    "## Useful links\n",
    "\n",
    "https://courses.helsinki.fi/fi/aycsm90004en/135221588 : \"Data Analysis with Python\" MOOC  \n",
    "http://www.learnpython.org/ : Nice interactive Python tutorial  \n",
    "https://docs.python.org/3/tutorial/index.html : Official documentation for Python3  \n",
    "https://docs.scipy.org/doc/numpy/user/quickstart.html : Tutorial for one of the most important Python modules, SciPy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Computing with floating point numbers\n",
    "\n",
    "Write a program to increment `x = 0.0` by `0.1` 100 times. Compute `x - 10`. How do you interpret the result?\n",
    "\n",
    "Check other examples with different increments. In which cases can you get an exact result? Can you come up with a class of instances where the result is exact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9539925233402755e-14\n"
     ]
    }
   ],
   "source": [
    "x = 0.0\n",
    "for i in range(100):\n",
    "    x += 0.1\n",
    "print(x - 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing probabilities\n",
    "\n",
    "Probabilities can sometimes be difficult to compute with floating point numbers as they can be very small non-negative numbers. These problems often be avoided by using logarithms and storing $ \\log(p) $ instead of $ p $.\n",
    "\n",
    "Compute numerically the following probabilities and report them in the format $x \\cdot 10^y$:\n",
    "1. The probability of randomly drawing the 8191-letter HIV-1 genome from the 4-letter DNA alphabet.\n",
    "2. The probability that you need at least 5000 throws of a regular 6-sided die to get the first 6. (Hint: Geometric distribution)\n",
    "3. The probability that $ x = 200 $ when $ x \\sim \\mathrm{Poisson}(1) $\n",
    "\n",
    "Hint: Python package 'numpy' contains basic numerical functions you will need. Just use 'np.log()' for log() etc. You can use the properties of logarithms to convert natural logarithms to base 10 to make them more human-readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 3.362103143113059 * 10^-4932.0\n",
      "p = 2.481988457849997 * 10^-397.0\n",
      "p = 4.664626530648222 * 10^-376.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to print the values in the requested format.\n",
    "# For all y, we have\n",
    "#   p = 10^logp = 10^y * 10^(logp - y)\n",
    "# where the logarithm is in base 10.\n",
    "# By choosing y to be largest integer not greater than logp, we have 1 <= x < 10\n",
    "def pretty_print_log10(logp):\n",
    "    y = np.floor(logp)\n",
    "    x = 10**(logp-y)\n",
    "    print(\"p = \" + str(x) + ' * 10^' + str(y))\n",
    "\n",
    "#1\n",
    "# Probability of drawing one letter from 4-letter alphabet is 1/4\n",
    "# Assuming probabilities are independent we get Pr(genome) = 0.25^8191\n",
    "logp_hiv = 8191*np.log10(0.25)\n",
    "pretty_print_log10(logp_hiv)\n",
    "\n",
    "#2\n",
    "# Probability for 4999 throws before first 6 is given by geometric distribution with p = 1/6\n",
    "logp_dice = 4999*np.log10(5/6)+np.log10(1/6)\n",
    "pretty_print_log10(logp_dice)\n",
    "\n",
    "#3\n",
    "# Probability for x=200 when x ~ Poisson(1) is given by exp(-1)/200!.\n",
    "# Logarithm of n! can be computed as the sum_i=1^n (log(i))\n",
    "logp_poi = -np.log10(np.exp(1)) - sum([np.log10(i+1) for i in range(200)])\n",
    "pretty_print_log10(logp_poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Numerical algorithms\n",
    "\n",
    "As an example of a numerical computation, let us consider the estimation of the variance of $ n $ numbers $ x_1, \\dots, x_n $.\n",
    "\n",
    "Denoting the mean of the numbers by $ \\bar{x}, $ the unbiased estimate of the sample variance is\n",
    "$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 =\n",
    "  \\frac{1}{n-1} \\sum_{i=1}^n (x_i^2 - 2 x_i \\bar{x} + \\bar{x}^2) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - 2 n \\bar{x}^2 + n \\bar{x}^2\\right) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - n \\bar{x}^2\\right) =\n",
    "  \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - \\frac{1}{n} (\\sum_{i=1}^n x_i)^2\\right).\n",
    "$$\n",
    "\n",
    "The variance can be estimated in a numerically stable manner using the first form, but this requires two passes through the data: first to compute the mean and then the second time to compute the sum of squared differences. The last form can be evaluated in single pass, but computing the difference of two potentially large positive numbers is numerically unstable.\n",
    "\n",
    "1. Write a function for computing the variance of a given array of numbers using the two-pass approach:\n",
    "$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i $$\n",
    "$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 $$\n",
    "2. Write a function for computing the variance of a given array of numbers using the one-pass approach:\n",
    "$$ s^2 = \\frac{1}{n-1} \\left(\\sum_{i=1}^n x_i^2 - \\frac{1}{n} (\\sum_{i=1}^n x_i)^2\\right). $$\n",
    "3. Test your functions by generating 1000 random number from the distribution $ N(10^9, 1) $. (Hint: 'numpy.random.randn()')\n",
    "4. Implement Welford's accurate one-pass algorithm and test it with your data. (See e.g. http://jonisalonen.com/2013/deriving-welfords-method-for-computing-variance/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9711208092807513\n",
      "-1705.6416416416416\n",
      "0.9711208503371113\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "#1\n",
    "# Slow two-pass implementation with loops\n",
    "def two_pass_loop(x):\n",
    "    mean = 0\n",
    "    n = len(x)\n",
    "    for x_i in x:\n",
    "        mean += x\n",
    "    mean /= n\n",
    "    variance = 0\n",
    "    for x_i in x:\n",
    "        variance += (x_i - mean)**2\n",
    "    variance /= n-1\n",
    "    return variance\n",
    "\n",
    "# Faster two-pass implementation using NumPy functions\n",
    "def two_pass(x):\n",
    "    n = len(x)\n",
    "    mean = np.mean(x)\n",
    "    variance = 1/(n-1)*np.sum((x-mean)**2)\n",
    "    return variance\n",
    "\n",
    "#2\n",
    "# Slow one-pass implementation with a loop\n",
    "def one_pass_loop(x):\n",
    "    n = len(x)\n",
    "    square_sum_x = 0\n",
    "    sum_x = 0\n",
    "    for x_i in x:\n",
    "        square_sum_x += x_i**2\n",
    "        sum_x += x_i\n",
    "    return (square_sum_x-sum_x**2/n)/(n-1)\n",
    "\n",
    "#3\n",
    "sample = npr.normal(1e9, 1, size=1000)\n",
    "print(two_pass(sample))  # variance of sample computed using two-pass approach\n",
    "print(one_pass_loop(sample))  # variance of sample computed using one-pass approach\n",
    "\n",
    "#4\n",
    "# NOTE: This pure Python implementation is inefficient - you should always use NumPy functions instead!\n",
    "def welfords(x):\n",
    "    m = 0\n",
    "    s = 0\n",
    "    for k, x_i in enumerate(x):\n",
    "        oldm = m\n",
    "        m += (x_i-m)/(k+1)\n",
    "        s+= (x_i-m)*(x_i-oldm)\n",
    "    return s/k # note that indexing of array in python starts from 0 and ends to length(array)-1\n",
    "                 # so at the end of for loop k=len(x)-1\n",
    "\n",
    "print(welfords(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Useful special functions\n",
    "\n",
    "Probability distributions often involve special functions such as the gamma function. The gamma function is also useful as $ n! = \\Gamma(n+1) $.\n",
    "\n",
    "1. Check the manual of the Python package 'scipy.special' to find the different forms of gamma function it offers.\n",
    "2. Redo task 3 of Exercise 2 using a suitable gamma function call from scipy.special."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 4.664626530648833 * 10^-376.0\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "from scipy.special import gammaln\n",
    "logp_poi = (-1 - gammaln(201))*np.log10(np.exp(1))\n",
    "pretty_print_log10(logp_poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tricks for computing with log-probabilities\n",
    "\n",
    "Assuming one is working with log-probabilities as suggested above, one often runs into the need to normalise a set of log-probabilities. To do this, it is necessary to compute\n",
    "$$ z = \\log\\left( \\sum_{i=1}^N \\exp(x_i) \\right). $$\n",
    "This can be difficult as $ \\exp() $ can very easily overflow or underflow. These problems can be avoided by using the log-sum-exp (or logsumexp) trick discussed e.g. at\n",
    "https://lips.cs.princeton.edu/computing-log-sum-exp/\n",
    "\n",
    "1. Try to compute $ z $ directly for $x = [-1000, -999, -1000]$.\n",
    "2. Compute $z$ again using the log-sum-exp trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "-998.448555286068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-64cee95dc9b4>:3: RuntimeWarning: divide by zero encountered in log\n",
      "  z1 = np.log(np.sum(np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "x = [-1000, -999, -1000]\n",
    "z1 = np.log(np.sum(np.exp(x)))\n",
    "print(z1)\n",
    "\n",
    "#2\n",
    "# log-sum-exp trick: subtract max(x) before taking exp() and add it back afterwards\n",
    "def logsumexp(x):\n",
    "    M = np.max(x)\n",
    "    return np.log(np.sum(np.exp(x-M)))+M\n",
    "\n",
    "z2 = logsumexp(x)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *6. Hidden Markov models (optional task if you have time)\n",
    "\n",
    "Hidden Markov models (or HMMs) are used commonly for modelling sequences of discrete symbols.\n",
    "\n",
    "http://www.cs.ubc.ca/~murphyk/Software/HMM/rabiner.pdf\n",
    "\n",
    "1. Implement the forward algorithm introduced in Sec. III-A of the Rabiner tutorial.\n",
    "2. Consider a model of the productivity of an author, George. George has good days and bad days. Good days are usually (70% of time) followed by another good day and bad days by another bad day (70% of time). The day when George starts is always a good day. On a good day George writes 1 page (50% of time) or 2 pages (50% of time). On a bad day he writes 0 pages (50% of time), 1 page (40% of time) or 2 pages (10% of time). Express the model of George's mood and productivity as a HMM.\n",
    "3. Consider a sequence of 10 years (3652 days) where George writes 1 page every single day. Test your algorithm for computing the probability of this sequence under the above HMM.\n",
    "4. Consider an alternative sequence where George's writing oscillates: $2^n 1^n 0^n 1^n 2^n 1^n 0^n 1^n \\dots$, where $k^n$ denotes a sequence of $n$ days when George writes $k$ pages. For which value of $n$ is this sequence most likely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2886.459087506795\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "def forward(O, pi, a, b):\n",
    "    # Initialize alphas\n",
    "    N = len(pi)\n",
    "    T = len(O)\n",
    "    log_alpha = np.empty(N)\n",
    "    for i in range(N):\n",
    "        if pi[i] > 0:\n",
    "            log_alpha[i] = np.log(pi[i]) + np.log(b[i,O[0]])\n",
    "        else:\n",
    "            log_alpha[i] = -np.inf # avoid warning if pi[i]=0\n",
    "    # Induction\n",
    "    if T>1:\n",
    "        for t in range(T-1):\n",
    "            log_alpha_old = np.copy(log_alpha)\n",
    "            for j in range(N):\n",
    "                #alpha[j] = np.sum(alpha_old*a[:,j])*b[j, O[t+1]]\n",
    "                log_alpha[j] = logsumexp(log_alpha_old+np.log(a[:,j])) + np.log(b[j, O[t+1]])\n",
    "    return logsumexp(log_alpha)\n",
    "\n",
    "#2\n",
    "pi_george = np.array([1.0, 0.0]) # Initialize Georges state\n",
    "a_george = np.array([[0.7, 0.3], [0.3, 0.7]]) # Transition probabilities\n",
    "b_george = np.array([[0.0,0.5,0.5],[0.5,0.4,0.1]]) # State probabilities\n",
    "\n",
    "#3\n",
    "O_george = np.ones(3652, dtype='int')\n",
    "logp = forward(O_george, pi_george, a_george, b_george)\n",
    "print(logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus extra: Early history of digital computers\n",
    "\n",
    "Statistics and computers have a long common history, and the first electronic computer Colossus was built by the British to perform statistical computations for breaking a German cryptosystem during World War II. This relatively unknown part of history is reported in detail in\n",
    "http://www.rutherfordjournal.org/article030109.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
